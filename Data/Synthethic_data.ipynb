{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset\n",
    "aus_groc = pd.read_csv('OriginalDataset/Australia_Grocery_2022Sep.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price randomizer over geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for synthesis\n",
    "prepare_syn = aus_groc[['Sku','city','state','Package_price']].sort_values(['Sku','city']).reset_index(drop=True)\n",
    "group_sku_city = prepare_syn.groupby('Sku').count()[['city']]\n",
    "group_sku_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geolocation data randomzier\n",
    "array_list = []\n",
    "for _, row in group_sku_city.iterrows():\n",
    "    # Create an array of zeros of the specified length\n",
    "    num_rows = row['city']\n",
    "    dummy_array = np.zeros(num_rows)\n",
    "    dummy_array[1:] = np.random.uniform(-0.15, 0.15, num_rows - 1)\n",
    "    dummy_array= np.around(dummy_array, decimals=2)\n",
    "    array_list.append(dummy_array)\n",
    "\n",
    "# Concatenate all the arrays into one big array\n",
    "big_array = np.concatenate(array_list)\n",
    "# Print the concatenated array's length and sample\n",
    "print(f\"Total length of the concatenated array: {len(big_array)}\")\n",
    "\n",
    "big_array\n",
    "\n",
    "new_price = prepare_syn.Package_price + prepare_syn.Package_price * big_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_syn['Package_price'] = new_price\n",
    "prepare_syn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Changes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a range of dates for the simulation\n",
    "start_date = pd.to_datetime(\"2022-11-09\")\n",
    "end_date = pd.to_datetime(\"2023-12-01\")\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Define the drift (daily average upward trend)\n",
    "daily_drift = 0.00013368061711349633  # Account for 5% inflation rate\n",
    "\n",
    "# Select unique store locations\n",
    "store_locations = prepare_syn[\"city\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to hold synthetic data for each store location\n",
    "synthetic_data_location = pd.DataFrame()\n",
    "\n",
    "# Create a DataFrame to store all synthetic data\n",
    "synthetic_data_location = []\n",
    "\n",
    "# Generate synthetic data for each unique SKU and location\n",
    "for location in store_locations:\n",
    "    # Filter data by location\n",
    "    location_data = prepare_syn[prepare_syn[\"city\"] == location]\n",
    "\n",
    "    # Get unique SKUs for the location\n",
    "    unique_skus = location_data[\"Sku\"].unique()\n",
    "\n",
    "    for sku in unique_skus:\n",
    "        # Filter data for the specific SKU in the location\n",
    "        sku_data = location_data[location_data[\"Sku\"] == sku]\n",
    "\n",
    "        if sku_data.empty:\n",
    "            continue  # Skip if no data for this SKU\n",
    "\n",
    "        # Base price to start the simulation\n",
    "        base_price = sku_data[\"Package_price\"].iloc[0]\n",
    "\n",
    "        # Generate synthetic price data using a random walk\n",
    "        prices = [base_price]\n",
    "        for _ in range(len(date_range) - 1):\n",
    "            change_percent = np.random.normal(daily_drift, 0.004)\n",
    "            new_price = prices[-1] * (1 + change_percent)\n",
    "            prices.append(max(new_price, 0))  # Ensure non-negative prices\n",
    "\n",
    "        # Create a data frame for the synthetic data\n",
    "        temp_df = pd.DataFrame({\n",
    "            \"Sku\": sku,\n",
    "            \"city\": location,\n",
    "            \"Package_price\": prices,\n",
    "            \"RunDate\": date_range\n",
    "        })\n",
    "\n",
    "        synthetic_data_location.append(temp_df)  # Store in a list\n",
    "\n",
    "# Concatenate all synthetic data into a single data frame\n",
    "synthetic_data_location = pd.concat(synthetic_data_location, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_location.to_csv('SynDataset/syn_data_loc_time.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
